{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4d35f6-d9f9-447f-862e-23112174a390",
   "metadata": {},
   "source": [
    "Der folgende Code pertubiert Bilder. Der Algorithmus basiert auf der in dem Paper https://arxiv.org/abs/1710.10547 beschriebene Top-K Attacke.\n",
    "\n",
    "Die Funktion pert nimmt das Ausgangsbild und die im Paper beschriebenen Parameter.<br>\n",
    "Die Funktion nimmt jedoch ein weiteren Parameter \"fix\" entgegen. Falls dieser Parameter True ist sind die Top-K Features fix und werden nicht in jeder Iteration neu bestimmt.\n",
    "\n",
    "Dieses Script nutzt die [crp2](crp2.yml) conda umgebung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b8140-1ac6-4dfd-b11a-e30551b9b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from zennit.attribution import Gradient\n",
    "from zennit.composites import EpsilonPlusFlat\n",
    "\n",
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "# This code doesnt work on mps, not tired on NVIDIA Cuda\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "imagenet_labels = models.VGG16_Weights.DEFAULT.meta[\"categories\"]\n",
    "\n",
    "weights=models.VGG16_BN_Weights.IMAGENET1K_V1.DEFAULT\n",
    "model = models.vgg16_bn(weights=weights).to(device)\n",
    "model.eval()\n",
    "\n",
    "imagenet_mean = torch.tensor([0.485, 0.456, 0.406], device=device)\n",
    "imagenet_std  = torch.tensor([0.229, 0.224, 0.225], device=device)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471fd5b-d06f-410c-a570-a3776cbe52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(t):\n",
    "    return (t - imagenet_mean[:, None, None]) / imagenet_std[:, None, None]\n",
    "\n",
    "def unnormalize(t):\n",
    "    return t * imagenet_std[:, None, None] + imagenet_mean[:, None, None]\n",
    "\n",
    "def load_image(path, device):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    return tensor\n",
    "\n",
    "def predict(model, inp_tensor):\n",
    "    with torch.no_grad():\n",
    "        logits = model(inp_tensor)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "    return pred, probs[0, pred].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e0d1e-abd7-4309-ae25-70417e55d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_positions_from_relevance(relevance, k, reverse):\n",
    "    a = relevance.detach().abs().sum(dim=1)  # (1,H,W)\n",
    "    flat = a.view(-1)\n",
    "    if k >= flat.numel():\n",
    "        idx = torch.arange(flat.numel(), device=flat.device)\n",
    "    else:\n",
    "        _, idx = torch.topk(flat, k, largest=not reverse)\n",
    "    H, W = a.shape[1], a.shape[2]\n",
    "    ys = (idx // W).long()\n",
    "    xs = (idx % W).long()\n",
    "    return ys.cpu().numpy(), xs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398486b-e682-4f25-b9d6-4111c0dab450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_topk_features(model, image_tensor_0_1, k, alpha, epsilon, fix=True, maxRetries=10, device=\"cpu\"):\n",
    "    model.to(device).eval()\n",
    "    img_norm = normalize(image_tensor_0_1.squeeze(0)).unsqueeze(0).to(device).clone().detach()\n",
    "    img_orig_norm = img_norm.clone().detach()\n",
    "\n",
    "    orig_pred, orig_conf = predict(model, img_norm)\n",
    "    print(f\"Original prediction: class {orig_pred}, confidence {orig_conf:.4f}\")\n",
    "\n",
    "    composite = EpsilonPlusFlat()\n",
    "    attributor = Gradient(model, composite, create_graph=True)\n",
    "\n",
    "    eps_norm = (epsilon / imagenet_std).view(3,1,1).to(device)\n",
    "    alpha_norm = (alpha / imagenet_std).view(3,1,1).to(device)\n",
    "\n",
    "    best_img = None\n",
    "    best_score = -float(\"inf\")\n",
    "    best_img2 = None\n",
    "    first_score = None\n",
    "    last_one = 0\n",
    "    was_last = False\n",
    "\n",
    "    ys = None\n",
    "    xs = None\n",
    "\n",
    "    pbar = trange(maxRetries, desc=\"Pertubiere Image\")\n",
    "    for attempt in pbar:\n",
    "        img_norm.requires_grad_(True)\n",
    "        with attributor:\n",
    "            output = model(img_norm)\n",
    "            target = F.one_hot(torch.tensor([orig_pred], device=device), num_classes=output.shape[1]).float()\n",
    "            _, relevance = attributor(img_norm, target)\n",
    "\n",
    "        if ys is None or not fix:\n",
    "            ys, xs = topk_positions_from_relevance(relevance, k, False)\n",
    "\n",
    "        topk_mask = torch.zeros_like(relevance, device=device)\n",
    "        for y, x in zip(ys, xs):\n",
    "            topk_mask[0, :, y, x] = 1.0\n",
    "\n",
    "        D = - (relevance * topk_mask).sum()\n",
    "        grad_D, = torch.autograd.grad(D, img_norm, retain_graph=False)\n",
    "\n",
    "        delta_norm = alpha_norm * torch.sign(grad_D)\n",
    "        delta_norm = - delta_norm\n",
    "        img_temp = img_norm + delta_norm\n",
    "        delta = img_temp - img_orig_norm\n",
    "        delta = torch.max(torch.min(delta, eps_norm), -eps_norm)\n",
    "        perturbed_norm = delta + img_orig_norm\n",
    "\n",
    "        perturbed_norm = (perturbed_norm).clamp(\n",
    "            (0 - imagenet_mean[:, None, None].to(device)) / imagenet_std[:, None, None].to(device),\n",
    "            (1 - imagenet_mean[:, None, None].to(device)) / imagenet_std[:, None, None].to(device)\n",
    "        )\n",
    "        \n",
    "        pred_new, conf_new = predict(model, perturbed_norm)\n",
    "\n",
    "        was_last = False\n",
    "        if pred_new == orig_pred:\n",
    "            with attributor:\n",
    "                output = model(perturbed_norm)\n",
    "                _, rel_new = attributor(perturbed_norm, target)\n",
    "            score = rel_new.abs().sum(dim=1)[0, ys, xs].sum().item()\n",
    "\n",
    "            best_img2 = perturbed_norm.detach()\n",
    "\n",
    "            was_last = True\n",
    "            if first_score is None:\n",
    "                first_score = score \n",
    "                \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_img = perturbed_norm.detach()\n",
    "                best_img2 = None\n",
    "                last_one = attempt\n",
    "        else:\n",
    "            print(\"Other Prediction\")\n",
    "                \n",
    "        img_norm = perturbed_norm.detach().clone().requires_grad_(True)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    if best_img is not None:\n",
    "        perturbed_unnorm = unnormalize(best_img.squeeze(0)).clamp(0.0,1.0).unsqueeze(0)\n",
    "        \n",
    "        delta_pixel = perturbed_unnorm - image_tensor_0_1\n",
    "        linf = delta_pixel.abs().max().item()\n",
    "        print(f\"Final: gleiche Klasse, minimale Top-k Relevanz {best_score:.6f} von {first_score:.6f}, L_inf {linf:.6f}, last one at {last_one}\")\n",
    "\n",
    "        img_norm = None if was_last else img_norm\n",
    "        return best_img, img_orig_norm, best_img2, img_norm, delta_pixel, True\n",
    "    else:\n",
    "        print(\"Keine erfolgreiche Perturbation gefunden.\")\n",
    "        return image_tensor_0_1, image_tensor_0_1, None, torch.zeros_like(image_tensor_0_1), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b66c0a-9c0d-441e-b2d5-4301291457fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pert(image_name, k, fix, maxRetries, alphaRawH, espilonRaw):\n",
    "    image_path = f\"images/{image_name}\"\n",
    "    img = load_image(image_path, device)\n",
    "    img_cpu = img.detach().cpu()\n",
    "    \n",
    "    epsilon = epsilonRaw / 255.0 \n",
    "    alpha = alphaRawH / 100.0 / 255.0\n",
    "\n",
    "    perturbed, original, maxPert, maximum, delta, ok = perturb_topk_features(model, img, k=k, fix=fix, alpha=alpha, epsilon=epsilon, maxRetries=maxRetries, device=device)\n",
    "\n",
    "    fixStr = \"_F\" if fix else \"\"\n",
    "    result_folder = f\"k{k}_retry{maxRetries}_alpha{alphaRawH}_epsilon{epsilonRaw}{fixStr}\"\n",
    "    print(result_folder)\n",
    "    result_path = f\"results/{image_name}/{result_folder}\"\n",
    "\n",
    "    isExist = os.path.exists(result_path)\n",
    "    if not isExist:\n",
    "       os.makedirs(result_path)\n",
    "\n",
    "    resultsToBeSaved = {\n",
    "        \"perturbed\": perturbed,\n",
    "        \"original\": original\n",
    "    }\n",
    "\n",
    "    for name, norm_tensor in resultsToBeSaved.items():\n",
    "        if norm_tensor is None:\n",
    "            continue\n",
    "        if name == \"original\":\n",
    "            name = \"../original\"\n",
    "        norm_tensor_cpu = norm_tensor.cpu()\n",
    "        torch.save(norm_tensor_cpu,f\"{result_path}/{name}.pt\")\n",
    "    \n",
    "        pixel_tensor = unnormalize(norm_tensor_cpu.squeeze(0)).clamp(0, 1).detach()\n",
    "        out = (pixel_tensor.permute(1,2,0).numpy() * 255.0).astype(np.uint8)\n",
    "    \n",
    "        img = Image.fromarray(out)\n",
    "        img.save(f\"{result_path}/{name}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d48c96-c0e2-4831-b69e-c8178552fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "maxRetries = 100\n",
    "alphaRawH = 6\n",
    "epsilonRaw = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170dcd03-0276-43d1-aaa0-23eb5fa03744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgNames = [\"beagle1.jpg\",\"dog.jpg\",\"eel1.jpg\",\"espresso.jpg\",\"goldfish.jpg\",\"lizard.jpg\",\"plane.png\",\"snail.png\", \"warplane.jpg\"]\n",
    "tryKs = [1, 10]\n",
    "fixs = [True]\n",
    "\n",
    "for i in imgNames:\n",
    "    for fix in fixs:\n",
    "        for k in tryKs:\n",
    "            pert(i, k, fix, maxRetries, alphaRawH, epsilonRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f276c3-60f3-46fe-aeb9-50c0f3c12316",
   "metadata": {},
   "source": [
    "You can use a sound to get a notification when calculation is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c6740-1802-47ec-a42a-cb06956ca199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "# This audio-file is not within the repo\n",
    "IPython.display.Audio(\"audio.mp3\", autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
